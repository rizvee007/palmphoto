# -*- coding: utf-8 -*-
"""SIFT_Algorithm for fingerprints.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1sjnRtClXHw23rM4s6p18xIeQpkLSXfA5
"""

import cv2 
import pickle
import matplotlib.pyplot as plt
import pandas as pd

!pip install opencv-contrib-python==4.4.0.44

"""###Resize Images function"""

# Resize images to a similar dimension
# This helps improve accuracy and decreases unnecessarily high number of keypoints

def imageResizeTrain(image):
    maxD = 1024
    height,width = image.shape
    aspectRatio = width/height
    if aspectRatio < 1:
        newSize = (int(maxD*aspectRatio),maxD)
    else:
        newSize = (maxD,int(maxD/aspectRatio))
    image = cv2.resize(image,newSize)
    return image

def imageResizeTest(image):
    maxD = 1024
    height,width,channel = image.shape
    aspectRatio = width/height
    if aspectRatio < 1:
        newSize = (int(maxD*aspectRatio),maxD)
    else:
        newSize = (maxD,int(maxD/aspectRatio))
    image = cv2.resize(image,newSize)
    return image

"""###Generate Keypoint and Descriptors

####Prepare list of images
"""

import numpy as np
import os

folder_dir = '/content/drive/MyDrive/hpoly_LeftHand/'
imageList = []

for file in os.listdir(folder_dir):
  if(file.endswith(".JPG")):
    file_name = os.path.basename(folder_dir + '/' + file)
    imageList.append(file_name)

print(imageList)

print(imageList)

len(imageList)

# # Define a list of images the way you like

# imageList = ['palm.jpg', 'palm1.jpg','palm2.jpg','palm3.jpg','palm4.jpg','palm5.jpg','palm6.jpg','palm7.jpg','palm8.jpg','palm9.jpg','palm10.jpg','palm11.jpg','palm12.jpg', 'palm13.jpg', 'palm14.jpg', 'palm15.jpg' , 'palm16.jpg','palm17.jpg', 'palm18.jpg',
#              'palm19.jpg', 'palm20.jpg', 'palm21.jpg','palm22.jpg','palm23.jpg','palm24.jpg','palm25.jpg','palm26.jpg','palm27.jpg','palm28.jpg','palm29.jpg','palm30.jpg']

from google.colab import drive
drive.mount('/content/drive')

# We use grayscale images for generating keypoints
imagesBW = []
for imageName in imageList:
    imagePath = "/content/drive/MyDrive/hpoly_LeftHand/" + str(imageName)
    imagesBW.append(imageResizeTrain(cv2.imread(imagePath,0)))

"""Choose between opencv's SIFT and open source SIFT implementation

"""

sift = cv2.xfeatures2d.SIFT_create()

def computeSIFT(image):
    return sift.detectAndCompute(image, None)

"""The following is the main function to generate the keypoints and descriptors

"""

keypoints = []
descriptors = []
i = 0
for image in imagesBW:
    print("Starting for image: " + imageList[i])
    keypointTemp, descriptorTemp = computeSIFT(image)
    keypoints.append(keypointTemp)
    descriptors.append(descriptorTemp)
    print("  Ending for image: " + imageList[i])
    i += 1

"""Store Keypoints and Descriptors for future use

"""

i = 0
for keypoint in keypoints:
    deserializedKeypoints = []
    filepath = "/content/drive/MyDrive/SIFT_ALGO/keypoints" + str(imageList[i].split('.')[0]) + ".txt"
    for point in keypoint:
        temp = (point.pt, point.size, point.angle, point.response, point.octave, point.class_id)
        deserializedKeypoints.append(temp)
    with open(filepath, 'wb') as fp:
        pickle.dump(deserializedKeypoints, fp)    
    i += 1

i = 0
for descriptor in descriptors:
    filepath = "/content/drive/MyDrive/SIFT_ALGO/descriptors" + str(imageList[i].split('.')[0]) + ".txt"
    with open(filepath, 'wb') as fp:
        pickle.dump(descriptor, fp)
    i += 1

"""Fetch Keypoints and Descriptors from stored files

"""

def fetchKeypointFromFile(i):
    filepath = "/content/drive/MyDrive/SIFT_ALGO/keypoints" + str(imageList[i].split('.')[0]) + ".txt"
    keypoint = []
    file = open(filepath,'rb')
    deserializedKeypoints = pickle.load(file)
    file.close()
    for point in deserializedKeypoints:
        temp = cv2.KeyPoint(x=point[0][0],y=point[0][1],_size=point[1], _angle=point[2], _response=point[3], _octave=point[4], _class_id=point[5])
        keypoint.append(temp)
    return keypoint

def fetchDescriptorFromFile(i):
    filepath = "/content/drive/MyDrive/SIFT_ALGO/descriptors" + str(imageList[i].split('.')[0]) + ".txt"
    file = open(filepath,'rb')
    descriptor = pickle.load(file)
    file.close()
    return descriptor

"""**Calculate Results for any pair**


"""

def calculateResultsFor(i,j):
    keypoint1 = fetchKeypointFromFile(i)
    descriptor1 = fetchDescriptorFromFile(i)
    keypoint2 = fetchKeypointFromFile(j)
    descriptor2 = fetchDescriptorFromFile(j)
    matches = calculateMatches(descriptor1, descriptor2)
    score = calculateScore(len(matches),len(keypoint1),len(keypoint2))
    plot = getPlotFor(i,j,keypoint1,keypoint2,matches)
    print(len(matches),len(keypoint1),len(keypoint2),len(descriptor1),len(descriptor2))
    print(score)
    plt.imshow(plot),plt.show()

    return score

def getPlotFor(i,j,keypoint1,keypoint2,matches):
    print(imageList)
    image1 = imageResizeTest(cv2.imread("/content/drive/MyDrive/hpoly_LeftHand/" + imageList[i]))
    image2 = imageResizeTest(cv2.imread("/content/drive/MyDrive/hpoly_LeftHand/" + imageList[j]))
    return getPlot(image1,image2,keypoint1,keypoint2,matches)

"""Scoring metric

####A score greater than 5 means very good
"""

def calculateScore(matches,keypoint1,keypoint2):
    return 100 * (matches/min(keypoint1,keypoint2))

bf = cv2.BFMatcher()
def calculateMatches(des1,des2):
    matches = bf.knnMatch(des1,des2,k=2)
    topResults1 = []
    for m,n in matches:
        if m.distance < 0.7*n.distance:
            topResults1.append([m])
            
    matches = bf.knnMatch(des2,des1,k=2)
    topResults2 = []
    for m,n in matches:
        if m.distance < 0.7*n.distance:
            topResults2.append([m])
    
    topResults = []
    for match1 in topResults1:
        match1QueryIndex = match1[0].queryIdx
        match1TrainIndex = match1[0].trainIdx

        for match2 in topResults2:
            match2QueryIndex = match2[0].queryIdx
            match2TrainIndex = match2[0].trainIdx

            if (match1QueryIndex == match2TrainIndex) and (match1TrainIndex == match2QueryIndex):
                topResults.append(match1)
    return topResults

def getPlot(image1,image2,keypoint1,keypoint2,matches):
    image1 = cv2.cvtColor(image1, cv2.COLOR_BGR2RGB)
    image2 = cv2.cvtColor(image2, cv2.COLOR_BGR2RGB)
    matchPlot = cv2.drawMatchesKnn(image1,keypoint1,image2,keypoint2,matches,None,[255,255,255],flags=2)
    return matchPlot

calculateResultsFor(2,9)

total_image = len(imageList)

# returning the score from calculateResultsFor
import numpy as np
narray = np.array([])

for image_number, image_name in enumerate(imageList):
  if image_number!=0:
    score = calculateResultsFor(165,image_number)
    
    narray_1 = np.array([score])
    narray = np.concatenate((narray, narray_1), axis =0)

print(narray)

result = np.count_nonzero(narray > 5)
print(result)



















"""For myself"""

##For good images
data = {'y_Actual':    ['palm.jpg', 'palm1.jpg','palm2.jpg','palm3.jpg','palm4.jpg','palm5.jpg','palm6.jpg','palm7.jpg','palm8.jpg','palm9.jpg','palm10.jpg',
                        'palm1.jpg','palm2.jpg','palm3.jpg','palm4.jpg','palm5.jpg','palm6.jpg','palm7.jpg','palm8.jpg','palm9.jpg','palm10.jpg','palm10.jpg',
                        'palm1.jpg','palm2.jpg','palm3.jpg','palm4.jpg','palm5.jpg'],
 
        'y_Predicted':    ['palm.jpg', 'palm1.jpg','palm2.jpg','palm3.jpg','palm4.jpg','palm5.jpg','palm6.jpg','palm7.jpg','palm8.jpg','palm9.jpg','palm10.jpg',
                           'palm11.jpg','palm12.jpg', 'palm11.jpg', 'palm14.jpg', 'palm15.jpg' , 'palm16.jpg','palm17.jpg', 'palm18.jpg', 'palm19.jpg', 'palm20.jpg', 
                           'palm21.jpg','palm22.jpg','palm23.jpg','palm24.jpg','palm25.jpg','palm26.jpg']
        }

df = pd.DataFrame(data, columns=['y_Actual','y_Predicted'])
print (df)

data['y_Predicted'].count('palm23.jpg')

